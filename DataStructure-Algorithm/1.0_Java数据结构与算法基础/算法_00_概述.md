增长速度: 2^n > n^3 > n^2 > nlogn > n > sqrt(n)-n的开方 > logn(几乎常数的时间)
要把n放到大的范围以上才成立，在一个小的n的范围，比如30，不成立.

对数的基本运算:

如果a^x=N，则x叫做以a为底N的对数,记做x=log(a)(N)，其中a要写于log右下。a叫做底数，N叫做真数。

通常我们将以10为底的对数叫做常用对数，并把log10N记为lgN.以无理数e=2.71828···为底数的对数，以e为底的对数称为自然对数（natural logarithm），并且把logeN 记为InN.

等价关系: aX=N <=> X=logaN

log(a)(1) = 0, log(a)(a) = 1, 

### 为什么不注明底数?

在数据结构和算法中，对数O(logn)一般不在表明具体的底数.因为在底数为常数的情况下
其实具体是多少，在这里是无所谓的：log(a)(n) = log(a)(b) * log(b)(n) = O(log(b)(n))
,这里的log(a)(b)是一个常数，所以这个常系数可以忽略掉.所以常底数无所谓.
我们说过在big-O
甚至严格地讲，在θ的意义上讲
这个常系数都是可以忽略掉的
所以我们说，具体到底是a还是b
其实是无所谓的
只要它们都是常数
与其如此，我们不如干脆就把它们忽略掉
不再具体标明

常数次幂也无所谓: c > 0, logn^c = c*logn = O(logn),所以c也可以忽略掉,相应地呢
还有，我们另一个特征就是
如果这个n，也就是问题的规模
本身是呈一个幂指数的形式
它有一个常数次方
我们说这个在log n的掩盖下
也是可以忽略掉的
原因也很简单
在高中就应该学过这个
n的肩膀上这个c是可以等价地
挪到log前边去，变成一个常系数
没错，又是常系数
所以它也是可以被忽略掉的

我们把logn叫poly-log function,这类算法，我们说也是非常高效.

c > 0, logn=O(n^c),对于任何一个多项式(n^c,c为常数，这就是一个多项式),logn都是可以在大O记号的意义下,被n的c次方所掩盖的.
所以它应该是，低于任何多项式的一个复杂度
从这个意义上讲 它本身应该是无限地接近于O(1)的
所以这种算法也是完全或者足以令我们满意的.

指数复杂度(2^n),和刚刚的多项式是有天壤之别的，n^c总是可以被O(2^n)所掩盖，这类指数算法的计算成本增长的是极其之快的.通常被认为是不可忍受的。

所以在指数O(2^n)和多项式O(n^c)之间有一个明显的分水岭(有效算法和无效算法的分水岭).可解的多项式问题成为有效算法

很多问题，它的O(2^n)指数形式算法往往显而易见，然而设计出O(n^c)算法却极其不易。

迭代的效率比递归要高.